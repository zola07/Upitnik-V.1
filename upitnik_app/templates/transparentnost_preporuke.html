<!DOCTYPE html>
<html>
<head>
    <title>Транспарентност</title>
    <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <img id="logo" src= "\static\pictures\logo-nitra-hor-cir.svg" alt= "png-image" />
    <br><br>
    <h2>Препоруке</h2>
    <br>
        <p>Могућност праћења – следљивост сматра се кључним захтевом за стварање поузданих и одговорних Система. Нове информационо-комуникационе технологије као што су:
            <br><br>
            <li>интернет ствари (енг. internet of things), </li>
            <li>рачунарство у облаку (енг. cloud computing) и мобилно рачунарство омогућиле су даљи развој приступа за обраду великих количина података (eng. big data) и алгоритама вештачке интелигенције. 
            <br><br>
            За разумевање и тумачење информација садржаних у скуповима података, потребно је извући важне чињенице и резоновати користећи знање и/или теорију вероватноће. Стога, Смернице разликују следљивост на нивоу:
        </p> 
        <br>  
            <li>порекла, приступа и екстракције података,</li>
            
            <li>алгоритама и модела за машинско учење</li>
            
            <li>процеса за аутоматску припрему и обраду података и процеса закључивања из идентификованих улазних фактора и излазних препорука релевантних за решавање проблема.</li>
           
            </p>
  <br>
            <p>Објашњивост се дефинише као „мера у којој су унутрашње стање и процеси доношења одлука

                у	аутономном систему доступни заинтересованим странама, укључујући и крајњег корисника система“. У случајевима када Систем има значајан утицај на животе људи, захтева се одговарајуће објашњење процеса доношења одлука које је благовремено и прилагођено стручности заинтересоване стране (нпр. лаика, регулатора или истраживача).
                
                Када су основни елементи за изградњу Система нетранспарентни (на пример: модел и процес учења), одлука заснована на вештачкој интелигенцији није интуитивна и објашњива. За многе „нетехничке” кориснике, интелигентни програм заснован на алгоритмима за машинско учење28 је „црна кутија”, на пример: неуронске мреже за препознавање образаца.
                
                Овај феномен црне кутије доводи до тога да корисници доводе у питање одлуке Система: Зашто сте то урадили? Зашто је ово резултат? Када сте успели или нисте постигли успех? Када могу да верујем? Овај рефлексивни скептицизам непосредно утиче на поверење корисника и ефикасност доношења одлука, чиме утиче и на усвајање решења вештачке интелигенције, укључујући финансијске и правне одлуке, медицинске дијагнозе, праћење индустријских процеса, безбедносни скрининг, запошљавање, правне пресуде, упис на универзитет, паметне куће и аутономна возила.
                
                Објашњивост се односи на оне технике вештачке интелигенције које корисницима Система (инжењерима вештачке интелигенције, крајњим корисницима и ревизорима) помажу да разумеју разлоге због којих модел производи своје резултате. Даље, објашњивост се односи и на оне технике који могу да обезбеде транспарентност у вези са улазним подацима, као и „разлогом“ који стоји иза употребе алгоритма који води до специфичног излаза. Сам алгоритам у овом случају не мора нужно бити откривен. Штавише, корак даље ка поузданој вештачкој интелигенцији је одговорна вештачка интелигенција, која поред објашњивости укључује и остале принципе које треба испунити приликом примене Система у практичним сценаријима: правичност (eng. fairness), усмереност на човека (енг. human-centric), свест о приватности (енг. privacy awareness, одговорност (енг. accountability), безбедност и сигурност (енг. safety and security).
                
                Док се поједини модели (статистички и дрва одлучивања) могу мапирати у правила и на тај начин обезбедити интерпретабилост резултата, то није случај с дубоким неуронским мрежама, које су нашле ширу примену нашле последњих година због све веће количине доступних података погодних за машинско учење. Последњи трендови везани за објашњиву вештачку интелигенцију подразумевају учења модела који су лакше објашњиви, коришћење мрежа неуралне логике, увођење интерпретабилних модела, коришћење графикона знања, итд.
            <br>
            <br>
                <h3>Комуникација</h3>
         
               
                Да би се обезбедило поштовање основних права и усклађеност са основним људским правима, а посебно правом на обавештеност, Системи морају бити препознатљиви као такви. Корисници морају бити обавештени да су у интеракцији са Системом, а, када је то потребно, и да имају избор да захтевају комуникацију с човеком.
                
                Корисност, делотворност, ефикасност и употребљивост Система обезбеђује се укључивањем крајњих корисника у дизајн, евалуацију и примену графичког корисничког интерфејса.
                
                Да би се обезбедила прецизна и експлицитна веза између апстрактних принципа које је Систем дужан да поштује и конкретних одлука о реализацији, примењује се препорука - етика по дизајну (енг. ethics-by-design). Већ се користе концепти „по дизајну”, на пример приватност по дизајну и безбедност по дизајну. Да би имали поверење у Систем неопходно је да буде разумљив и објашњив лицима која га примењују и користе, као и безбедан у свим својим процесима.
                
                </p>
                <br>
            
            <a id="button" href="/transparentnost">Врати се назад</a></li>
            <a id="button" href="/razlicitost_nediskriminacija_i_ravnopravnost">Следећа група питања</a></li>
</body>
</html>
